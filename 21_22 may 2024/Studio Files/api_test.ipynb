{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from jsonargparse import CLI\n",
    "\n",
    "server_url = \"https://8000-01hy7ksszs01eppcc804p9yjrh.cloudspaces.litng.ai/predict\"\n",
    "\n",
    "\n",
    "def send_image_to_server(prompt: str, image_path:str):\n",
    " \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Convert the image to bytes\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    image_bytes = buffered.getvalue()\n",
    "\n",
    "    headers = {\"Authorization\": \"Bearer llmops\"}\n",
    "    response = requests.post(\n",
    "        server_url,\n",
    "        json={\n",
    "            \"image_bytes\": image_bytes.hex(),  # Convert bytes to hex string for JSON serialization\n",
    "            \"prompt\": prompt,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Print the response from the server\n",
    "    if response.status_code == 200:\n",
    "        out=response.json()\n",
    "        return out[\"output\"]\n",
    "    else:\n",
    "        print(\n",
    "            \"Failed to get response from the server, status code:\", response.status_code\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A black and white dog and a gray and white cat are standing side by side on a yellow background. The dog has a black and white striped collar and its tongue is sticking out. The cat has green eyes and its ears are perked up. The dog is wearing a tie and the cat is looking at the camera. The two animals are together and looking at the viewer.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"dog.jpg\"\n",
    "prompt = \"what is in this image?\"\n",
    "send_image_to_server(image_path=image_path, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 3 8b instruct (VLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_url=\"https://8001-01hy7ksszs01eppcc804p9yjrh.cloudspaces.litng.ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at the Globe Life Field in Arlington, Texas.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "# openai_api_base = \"http://localhost:8000/v1\"\n",
    "openai_api_base=\"https://8000-01hy7ksszs01eppcc804p9yjrh.cloudspaces.litng.ai/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Who won the world series in 2020?\"\n",
    "    }, {\n",
    "        \"role\":\n",
    "        \"assistant\",\n",
    "        \"content\":\n",
    "        \"The Los Angeles Dodgers won the World Series in 2020.\"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Where was it played?\"\n",
    "    }],\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using with litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at Globe Life Field in Arlington, Texas, which is the home of the Texas Rangers. The series was played in a neutral site due to the COVID-19 pandemic, as the Dodgers and Tampa Bay Rays did not have a home-field advantage.\n"
     ]
    }
   ],
   "source": [
    "import litellm \n",
    "messages=messages=[{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Who won the world series in 2020?\"\n",
    "    }, {\n",
    "        \"role\":\n",
    "        \"assistant\",\n",
    "        \"content\":\n",
    "        \"The Los Angeles Dodgers won the World Series in 2020.\"\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Where was it played?\"\n",
    "    }]\n",
    "\n",
    "response = litellm.completion(\n",
    "            model=\"openai/meta-llama/Meta-Llama-3-8B-Instruct\", # pass the vllm model name\n",
    "            messages=messages,\n",
    "            api_key=\"sk-1234\",\n",
    "            api_base=\"https://8000-01hy7ksszs01eppcc804p9yjrh.cloudspaces.litng.ai/v1\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=80)\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 3 8b instruct (TGI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subfield of artificial intelligence (AI) that involves the use of artificial neural networks to analyze and interpret data. These networks are composed of multiple layers of interconnected nodes or \"neurons,\" hence the term \"deep\" learning.\n",
      "\n",
      "In deep learning, these artificial neural networks are designed to mimic the structure and function of the human brain, in which complex patterns and relationships are learned through the interactions of multiple layers of neurons. This allows deep learning algorithms to learn and represent increasingly abstract and nuanced\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# init the client but point it to TGI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/v1\",\n",
    "    api_key=\"-\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"tgi\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "        {\"role\": \"user\", \"content\": \"What is deep learning?\"}\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLLAMA with LLAMA 3 8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a great question!\n",
      "\n",
      "The color of the sky can appear different depending on various factors, such as:\n",
      "\n",
      "1. **Time of day**: During sunrise and sunset, the sky can take on hues of red, orange, pink, and purple due to the scattering of light by atmospheric particles.\n",
      "2. **Atmospheric conditions**: On clear days, the sky appears blue because the shorter wavelengths of light (like blue and violet) are scattered more than the longer wavelengths (like red and orange). However, if there's pollution or dust in the air, the sky can appear hazy or gray.\n",
      "3. **Altitude and atmospheric layers**: From a plane or high altitude, the sky can appear darker blue to almost black due to the reduced amount of scattering particles.\n",
      "4. **Weather systems**: During thunderstorms or severe weather events, the sky can take on various shades of gray, brown, or even greenish hues.\n",
      "\n",
      "So, what is the \"standard\" color of the sky? Well...\n",
      "\n",
      "In ideal conditions, with a clear blue sky and no atmospheric distortion, the sky typically appears:\n",
      "\n",
      "* **Cerulean**: A bright, calming shade of blue, often described as a gentle, serene blue.\n",
      "* **Azure**: A deeper, richer blue, often associated with a clear summer sky.\n",
      "\n",
      "These colors can vary depending on your location and the time of day. But in general, the color of the sky is a wonderful combination of blue hues!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'what is the color of sky?',\n",
    "        }\n",
    "    ],\n",
    "    model='llama3:8b',\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
